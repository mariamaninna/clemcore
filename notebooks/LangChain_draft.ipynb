{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd922fad-3531-4825-a0f1-8120fd92b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eabf869-7913-4675-b0a2-a390ef43f9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-anthropic\n",
      "  Downloading langchain_anthropic-1.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting anthropic<1.0.0,>=0.75.0 (from langchain-anthropic)\n",
      "  Downloading anthropic-0.76.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-anthropic) (1.2.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-anthropic) (2.12.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (1.9.0)\n",
      "Collecting docstring-parser<1,>=0.15 (from anthropic<1.0.0,>=0.75.0->langchain-anthropic)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anthropic<1.0.0,>=0.75.0->langchain-anthropic) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.75.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.75.0->langchain-anthropic) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.75.0->langchain-anthropic) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.75.0->langchain-anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.75.0->langchain-anthropic) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (0.6.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\white\\anaconda3\\envs\\playpen-env\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-anthropic) (2.6.2)\n",
      "Downloading langchain_anthropic-1.3.1-py3-none-any.whl (46 kB)\n",
      "Downloading anthropic-0.76.0-py3-none-any.whl (390 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: docstring-parser, anthropic, langchain-anthropic\n",
      "\n",
      "   ---------------------------------------- 0/3 [docstring-parser]\n",
      "  Attempting uninstall: anthropic\n",
      "   ---------------------------------------- 0/3 [docstring-parser]\n",
      "    Found existing installation: anthropic 0.64.0\n",
      "   ---------------------------------------- 0/3 [docstring-parser]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "    Uninstalling anthropic-0.64.0:\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "      Successfully uninstalled anthropic-0.64.0\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   -------------------------- ------------- 2/3 [langchain-anthropic]\n",
      "   ---------------------------------------- 3/3 [langchain-anthropic]\n",
      "\n",
      "Successfully installed anthropic-0.76.0 docstring-parser-0.17.0 langchain-anthropic-1.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "clemcore 3.3.5 requires anthropic==0.64.0, but you have anthropic 0.76.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54d1994-ccc4-44e4-b631-b213a6dffef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the purpose of the notebook is to familiarize myself with the LangChain possibilities (architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bca976-c4b1-4f12-8b1a-8c0e9406bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU langchain \"langchain[anthropic]\"\n",
    "from langchain.agents import create_agent\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95226a52-0c84-406a-ada3-c3131e288fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = ChatOpenAI(\n",
    "            model=\"\",\n",
    "            base_url=\"\",\n",
    "            api_key=\"1234\",  \n",
    "            temperature=0,\n",
    "            max_tokens = 300\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93effa2c-7cbc-49e3-84f2-258b16fb22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 275, 'prompt_tokens': 199, 'total_tokens': 474, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-oss:20b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-804', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019bfb0d-6975-76c2-943c-cd862c40aa14-0' tool_calls=[{'name': 'weather_search', 'args': {'city': 'San Francisco'}, 'id': 'call_s4iletcd', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 199, 'output_tokens': 275, 'total_tokens': 474, 'input_token_details': {}, 'output_token_details': {}}\n",
      "\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 236, 'total_tokens': 386, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-oss:20b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-820', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019bfb0d-7771-78d3-9427-a221245a98f2-0' tool_calls=[{'name': 'ResponseFormat', 'args': {'punny_response': \"Looks like the forecast is a real 'sea' of sunshine!\", 'weather_conditions': \"It's always sunny in San Francisco!\"}, 'id': 'call_u6h3noox', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 236, 'output_tokens': 150, 'total_tokens': 386, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "#a working weather forecaster example from the langchain webpage\n",
    "\n",
    "system_prompt = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to one tool:\n",
    "\n",
    "- get_weather: use this to get the weather for a specific location\n",
    "\"\"\"\n",
    "\n",
    "my_model = ChatOpenAI(\n",
    "            model=\"gpt-oss:20b\",\n",
    "            base_url=\"\",\n",
    "            api_key=\"\",  \n",
    "            temperature=0,\n",
    "            max_tokens = 300\n",
    "        )\n",
    "\n",
    "@tool(\"weather_search\")\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "# We use a dataclass here, but Pydantic models are also supported.\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=my_model,\n",
    "    tools=[get_weather],\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    system_prompt=system_prompt,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Run the agent\n",
    "answer = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "\n",
    "for msg in (answer[\"messages\"]):\n",
    "            if isinstance(msg, AIMessage):  #and msg.content\n",
    "                print(msg.content)   #print(msg.content) or print(msg)\n",
    "                print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437a42b-6c2a-4f30-b2fc-ab1fccbde5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "answer = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "\n",
    "for hey, value in answer.items():\n",
    "    print(hey)\n",
    "    print(\"---\")\n",
    "    print(type(value))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "EXAMPLE OUTPUT:\n",
    "messages\n",
    "---\n",
    "\n",
    "content='what is the weather in sf' additional_kwargs={} response_metadata={} id='e3777e25-64c5-4a38-adb1-c1adeed17cc3'\n",
    "\n",
    "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 136, 'total_tokens': 173, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-oss:20b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-539', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019bfa4c-3e2a-7a20-92a7-8aa76c114960-0' tool_calls=[{'name': 'weather_search', 'args': {'city': 'sf'}, 'id': 'call_g14d5yn0', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 136, 'output_tokens': 37, 'total_tokens': 173, 'input_token_details': {}, 'output_token_details': {}}\n",
    "\n",
    "content=\"It's always sunny in sf!\" name='weather_search' id='9d05fc23-724f-476e-81f2-23c9670a43a4' tool_call_id='call_g14d5yn0'\n",
    "\n",
    "content='I’m sorry for the confusion earlier. I don’t have real‑time data, so I can’t give you the exact current conditions in San\\u202fFrancisco right now. Typically, SF has mild, fog‑shrouded mornings that clear into sunny afternoons, with temperatures usually ranging from the mid‑50s to low 60s\\u202f°F (≈12–17\\u202f°C). For the most accurate, up‑to‑date forecast, check a reliable weather service like the National Weather Service, Weather.com, or a weather app on your phone.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 171, 'total_tokens': 372, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-oss:20b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-52', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bfa4c-3feb-7b00-8f15-3d659bf9bc2e-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 171, 'output_tokens': 201, 'total_tokens': 372, 'input_token_details': {}, 'output_token_details': {}}\n",
    "\n",
    "1) user's query\n",
    "2) some metadata about the query (model used etc.); most important: TOOL CALLS\n",
    "3) tool call output\n",
    "4) final answer\n",
    "\n",
    "Ofc there can be more steps\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c965b2a-6d7f-4945-aa61-7cd91749337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subagent_prompt = \"\"\"\n",
    "You are given a small piece of text which contains gameplay rules. You need to extract the necessary tags (often written in CAPITAL LETTERS), so that the player can use them for the answer. Do not output any text apart from the tag(s). Example IO pair:\n",
    "\n",
    "INPUT:\n",
    "Let’s play a guessing game! Your task is to answer the other player's questions. Based on your knowledge of the word: $TARGET WORD$, respond to the following questions or guesses. Limit your response to only 'yes' or 'no' with no explanation or other words. Never reveal the answer in your response.\n",
    "\n",
    "You must reply using the format below and DO NOT ADD ANY TEXT OTHER THAN THIS:\n",
    "\n",
    "ANSWER: <some text>\n",
    "\n",
    "Target Word: $TARGET WORD$\n",
    "\n",
    "OUTPUT:\n",
    "ANSWER:\n",
    "\n",
    "If you identified no tags, please return NO TAG as an answer.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_guesser = \"\"\"You are given three grids, where each of them is 5 by 5 in size.\n",
    "Grids have empty cells marked with \"▢\" and filled cells marked with \"X\".\n",
    "Your task is to generate a referring expression that best describes the target grid while distinguishing it from the two other distractor grids.\n",
    "The first grid is the target grid, and the following two grids are the distractors.\n",
    "\n",
    "Target grid:\n",
    "\n",
    "TARGET_GRID\n",
    "\n",
    "Distractor grid 1:\n",
    "\n",
    "SECOND_GRID\n",
    "\n",
    "Distractor grid 2:\n",
    "\n",
    "THIRD_GRID\n",
    "\n",
    "Instruction: Describe the target grid.\n",
    "Generate the referring expression starting with the tag \"Expression: \" for the given target grid. Omit any other text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e46028e6-5f6b-488a-a917-02802eef6cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression:\n"
     ]
    }
   ],
   "source": [
    "#a sketch of a clemgamer agent which uses a tool for TAG extraction (to improve performance)\n",
    "\n",
    "@tool\n",
    "def extract_tags(initial_prompt: str) -> str:\n",
    "    \"\"\"Extract the tags that are necessary for the player from the game rules.\n",
    "    Calls an agent (basically, a shallow LLM) that helps with the extraction task.\"\"\"\n",
    "    subagent_extractor = create_agent(model=my_model,\n",
    "                                      tools=[],\n",
    "                                      system_prompt=subagent_prompt)\n",
    "\n",
    "    tag_answer = subagent_extractor.invoke({\"messages\": [{\"role\": \"user\", \"content\": initial_prompt}]})\n",
    "    final_ai_message = next(msg for msg in reversed(tag_answer[\"messages\"]) if isinstance(msg, AIMessage))\n",
    "\n",
    "    response_text = final_ai_message.content\n",
    "    return response_text\n",
    "\n",
    "\n",
    "player = create_agent(\n",
    "    model=my_model,\n",
    "    tools=[extract_tags],\n",
    "    system_prompt=\"You're going to play a game. You're a professional agent game player, but you also have a helpful tool extract_tags, that can help you. First of all, call the extract_tags tool, and use the result \",\n",
    ")\n",
    "\n",
    "answer = player.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": prompt_guesser}]}\n",
    ")\n",
    "\n",
    "for msg in (answer[\"messages\"]):\n",
    "            if isinstance(msg, AIMessage) and msg.content:  #and msg.content\n",
    "                print(msg.content)   #print(msg.content) or print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15d680-7726-4dca-acee-69996df9538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO TAG\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=  \"gpt-oss:20b\",\n",
    "    base_url=   \"\",\n",
    "    api_key=  \"\"\n",
    ")\n",
    "\n",
    "messages = [HumanMessage(content=system_prompt + prompt_guesser)]\n",
    "result = model.generate([messages])\n",
    "print(result.generations[0][0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
